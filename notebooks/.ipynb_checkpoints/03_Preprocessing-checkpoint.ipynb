{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3db7fd65-7027-4d6d-b4ae-21b96c03da8d",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis - covariants\n",
    "by __Pawel Rosikiewicz__ \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61adb3d9-bc05-43a1-8b09-36a1ec84e53c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "485fffe1-fdd9-45de-85dd-f1c1b6387b35",
   "metadata": {},
   "source": [
    "## Setup\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a45e9ed-9f62-4c52-ab23-68728efbdae1",
   "metadata": {},
   "source": [
    "__global imports__\n",
    "* I purposely placed other imports, such as my custom made functions for thsi project in each section\n",
    "* to allow you fast inspection of my code, but also, copying these important to new notebooks, for pipeline development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7867b0ed-9c91-4663-958b-1e0c89518e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re # module to use regular expressions, \n",
    "import glob # lists names in folders that match Unix shell patterns\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn import set_config\n",
    "from sklearn.preprocessing import RobustScaler # creates custom transfomers\n",
    "from sklearn.preprocessing import FunctionTransformer # creates custom transfomers\n",
    "from sklearn.pipeline import make_pipeline, Pipeline # like pipeline function, but give step names automatically, \n",
    "from sklearn.compose import ColumnTransformer # allows using different transformers to different columns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, KBinsDiscretizer # skleanr transformers,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49f97e81-2ce9-4db4-b815-c5307d5e34a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basedir\n",
    "basedir = os.path.dirname(os.getcwd())\n",
    "os.chdir(basedir)\n",
    "sys.path.append(basedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49f566f6-a9b0-4528-aa7b-d86d9598069c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "PATH_data_raw     = os.path.join(basedir, \"data/raw\")\n",
    "PATH_data_interim = os.path.join(basedir, \"data/interim\")\n",
    "PATH_results      = os.path.join(basedir, \"data/results\")\n",
    "PATH_models       = os.path.join(basedir, \"models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d32537e-4f11-4e58-b88a-ef97858d40ab",
   "metadata": {},
   "source": [
    "__load functions, and classes created for that project__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8e900b7b-74bf-4563-a784-4793e758cf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.helper_data_loaders import load_tsv\n",
    "\n",
    "# helper function for qc and piepline calibration\n",
    "from src.utils.helper_tpm_summary import tpm_summary\n",
    "from src.utils.helper_tpm_summary import tpm_plots\n",
    "from src.utils.helper_cluster_histogram import spearman_clustermap\n",
    "from src.utils.helper_boxplot import colored_boxplots\n",
    "from src.utils.helper_colored_boxplot import plot_colored_boxplot\n",
    "from src.utils.helper_gene_expression_clustermap import gene_expression_clustermap\n",
    "\n",
    "# my custom transformers\n",
    "from src.utils.preprocessing_spearman_filter import SpearmanFilter # to remove sample outliers, \n",
    "from src.utils.preprocessing_zero_value_filter import ZeroValueFilter # to remove genes with no tpm in most of the samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955539c3-7f9d-41c8-a685-397d5f070afa",
   "metadata": {},
   "source": [
    "__configurations__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9dba6803-8f8e-4153-b5fd-a38bd695674d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main variable groups, and types\n",
    "VAR_GROUPS = dict(\n",
    "    TARGET_VAR = [\"target\"],\n",
    "    CATEGORICAL_VAR = [ 'Baseline ECOG Score', 'Enrollment IC', 'IC Level', 'TC Level', 'Immune phenotype', 'Sex',\n",
    "           'TCGA Subtype', 'Lund', 'Lund2', 'Received platinum',\n",
    "           'Met Disease Status', 'Sample age', 'Sample collected pre-platinum',\n",
    "           'Intravesical BCG administered', 'Tobacco Use History'],\n",
    "    QUANTITATIVE_VAR = ['FMOne mutation burden per MB', 'Neoantigen burden per MB'],\n",
    ")\n",
    "\n",
    "# variable encoding in data_cov\n",
    "VAR_DTYPES = {\n",
    "    \"TARGET_VAR\": \"int\", # only for EDA\n",
    "    \"CATEGORICAL_VAR\": \"O\",\n",
    "    \"QUANTITATIVE_VAR\": \"float64\"\n",
    "}\n",
    "\n",
    "# target variable encoding\n",
    "TARGET_ENCODING = {0:\"non-responder\", 1:\"responder\"}\n",
    "\n",
    "# list potential confounding variables, used to stratify the results\n",
    "CONFOUNDING_VAR = ['Sex', 'Tobacco Use History']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e105a691-4d37-4923-8ac4-667af10c3a5c",
   "metadata": {},
   "source": [
    "## PART 1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "533ac09a-64ae-4535-b410-0404b15abb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 17)\n",
      "(200, 31085)\n",
      "(200, 1)\n"
     ]
    }
   ],
   "source": [
    "# load target data\n",
    "data_cov =  load_tsv(PATH_data_raw, 'X_covariates.tsv')\n",
    "data_genes = load_tsv(PATH_data_raw, 'X_genes.tsv')\n",
    "target = load_tsv(PATH_data_raw, 'y.tsv', header=None)\n",
    "\n",
    "# small correction\n",
    "target.columns=[VAR_GROUPS[\"TARGET_VAR\"][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14f8b8bc-51c1-4969-bb2d-2c28e193fc93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (200, 31085)\n",
      "missing data nr: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPM_hugo_A1BG</th>\n",
       "      <th>TPM_hugo_A1BG-AS1</th>\n",
       "      <th>TPM_hugo_A1CF</th>\n",
       "      <th>TPM_hugo_A2M</th>\n",
       "      <th>TPM_hugo_A2M-AS1</th>\n",
       "      <th>TPM_hugo_A2ML1</th>\n",
       "      <th>TPM_hugo_A2MP1</th>\n",
       "      <th>TPM_hugo_A3GALT2</th>\n",
       "      <th>TPM_hugo_A4GALT</th>\n",
       "      <th>TPM_hugo_A4GNT</th>\n",
       "      <th>...</th>\n",
       "      <th>TPM_hugo_ZWILCH</th>\n",
       "      <th>TPM_hugo_ZWINT</th>\n",
       "      <th>TPM_hugo_ZXDA</th>\n",
       "      <th>TPM_hugo_ZXDB</th>\n",
       "      <th>TPM_hugo_ZXDC</th>\n",
       "      <th>TPM_hugo_ZYG11A</th>\n",
       "      <th>TPM_hugo_ZYG11B</th>\n",
       "      <th>TPM_hugo_ZYX</th>\n",
       "      <th>TPM_hugo_ZZEF1</th>\n",
       "      <th>TPM_hugo_ZZZ3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.564289</td>\n",
       "      <td>2.711834</td>\n",
       "      <td>0.0</td>\n",
       "      <td>599.387994</td>\n",
       "      <td>2.354073</td>\n",
       "      <td>43.245808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.437090</td>\n",
       "      <td>0.070903</td>\n",
       "      <td>...</td>\n",
       "      <td>8.574489</td>\n",
       "      <td>6.467672</td>\n",
       "      <td>1.906227</td>\n",
       "      <td>3.293924</td>\n",
       "      <td>8.333586</td>\n",
       "      <td>2.189232</td>\n",
       "      <td>19.280571</td>\n",
       "      <td>168.266220</td>\n",
       "      <td>27.175332</td>\n",
       "      <td>17.836860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.487859</td>\n",
       "      <td>1.717013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>222.711937</td>\n",
       "      <td>2.288359</td>\n",
       "      <td>5.718716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.564476</td>\n",
       "      <td>6.026609</td>\n",
       "      <td>0.108688</td>\n",
       "      <td>...</td>\n",
       "      <td>10.409939</td>\n",
       "      <td>3.572365</td>\n",
       "      <td>2.761780</td>\n",
       "      <td>3.411667</td>\n",
       "      <td>9.293182</td>\n",
       "      <td>1.813353</td>\n",
       "      <td>21.761841</td>\n",
       "      <td>66.403339</td>\n",
       "      <td>21.311923</td>\n",
       "      <td>22.296492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.613334</td>\n",
       "      <td>0.508520</td>\n",
       "      <td>0.0</td>\n",
       "      <td>204.222937</td>\n",
       "      <td>0.627338</td>\n",
       "      <td>300.472716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.797474</td>\n",
       "      <td>0.040773</td>\n",
       "      <td>...</td>\n",
       "      <td>6.272013</td>\n",
       "      <td>3.109443</td>\n",
       "      <td>1.068439</td>\n",
       "      <td>2.559726</td>\n",
       "      <td>5.181549</td>\n",
       "      <td>0.225283</td>\n",
       "      <td>15.800051</td>\n",
       "      <td>172.944084</td>\n",
       "      <td>14.743828</td>\n",
       "      <td>18.920023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.385017</td>\n",
       "      <td>1.600782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1851.589619</td>\n",
       "      <td>3.301540</td>\n",
       "      <td>1.346349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.938826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.586123</td>\n",
       "      <td>1.150169</td>\n",
       "      <td>1.464567</td>\n",
       "      <td>1.386418</td>\n",
       "      <td>4.501980</td>\n",
       "      <td>0.036808</td>\n",
       "      <td>11.444219</td>\n",
       "      <td>116.271619</td>\n",
       "      <td>19.222790</td>\n",
       "      <td>11.936066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.964353</td>\n",
       "      <td>0.791064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>982.752783</td>\n",
       "      <td>0.589165</td>\n",
       "      <td>85.088254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096887</td>\n",
       "      <td>17.058419</td>\n",
       "      <td>0.447727</td>\n",
       "      <td>...</td>\n",
       "      <td>4.292896</td>\n",
       "      <td>2.469881</td>\n",
       "      <td>1.809374</td>\n",
       "      <td>3.056738</td>\n",
       "      <td>6.604204</td>\n",
       "      <td>0.436553</td>\n",
       "      <td>20.036719</td>\n",
       "      <td>143.793153</td>\n",
       "      <td>24.820985</td>\n",
       "      <td>17.297542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31085 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TPM_hugo_A1BG  TPM_hugo_A1BG-AS1  TPM_hugo_A1CF  TPM_hugo_A2M  \\\n",
       "0       1.564289           2.711834            0.0    599.387994   \n",
       "1       3.487859           1.717013            0.0    222.711937   \n",
       "2       0.613334           0.508520            0.0    204.222937   \n",
       "3       2.385017           1.600782            0.0   1851.589619   \n",
       "4       1.964353           0.791064            0.0    982.752783   \n",
       "\n",
       "   TPM_hugo_A2M-AS1  TPM_hugo_A2ML1  TPM_hugo_A2MP1  TPM_hugo_A3GALT2  \\\n",
       "0          2.354073       43.245808             0.0          0.000000   \n",
       "1          2.288359        5.718716             0.0          0.564476   \n",
       "2          0.627338      300.472716             0.0          0.000000   \n",
       "3          3.301540        1.346349             0.0          0.000000   \n",
       "4          0.589165       85.088254             0.0          0.096887   \n",
       "\n",
       "   TPM_hugo_A4GALT  TPM_hugo_A4GNT  ...  TPM_hugo_ZWILCH  TPM_hugo_ZWINT  \\\n",
       "0        11.437090        0.070903  ...         8.574489        6.467672   \n",
       "1         6.026609        0.108688  ...        10.409939        3.572365   \n",
       "2        11.797474        0.040773  ...         6.272013        3.109443   \n",
       "3        23.938826        0.000000  ...         4.586123        1.150169   \n",
       "4        17.058419        0.447727  ...         4.292896        2.469881   \n",
       "\n",
       "   TPM_hugo_ZXDA  TPM_hugo_ZXDB  TPM_hugo_ZXDC  TPM_hugo_ZYG11A  \\\n",
       "0       1.906227       3.293924       8.333586         2.189232   \n",
       "1       2.761780       3.411667       9.293182         1.813353   \n",
       "2       1.068439       2.559726       5.181549         0.225283   \n",
       "3       1.464567       1.386418       4.501980         0.036808   \n",
       "4       1.809374       3.056738       6.604204         0.436553   \n",
       "\n",
       "   TPM_hugo_ZYG11B  TPM_hugo_ZYX  TPM_hugo_ZZEF1  TPM_hugo_ZZZ3  \n",
       "0        19.280571    168.266220       27.175332      17.836860  \n",
       "1        21.761841     66.403339       21.311923      22.296492  \n",
       "2        15.800051    172.944084       14.743828      18.920023  \n",
       "3        11.444219    116.271619       19.222790      11.936066  \n",
       "4        20.036719    143.793153       24.820985      17.297542  \n",
       "\n",
       "[5 rows x 31085 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect\n",
    "print(\"shape:\", data_genes.shape)\n",
    "print(\"missing data nr:\", data_genes.isnull().sum().sum())\n",
    "\n",
    "# get example\n",
    "data_genes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad4485e-e062-476d-ba2c-b512778eaabf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b100cbaa-fc53-4fb6-9688-c82e903170ac",
   "metadata": {},
   "source": [
    "## PART 2. Establish Proeprocessing Pipeline\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ee30c7-8531-4d5b-9fb1-1c27cb8c6c0a",
   "metadata": {},
   "source": [
    "__set up low level tranformers and helper funcitons for preprocessor__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "57b7fd5d-a1a8-4b95-a395-a0e86e26b496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function, .................................\n",
    "def transpose_rebuild(transposed_arr, df):\n",
    "    ''' tranpose aarr, and adds col/row names \n",
    "        to it aftem making dataframe\n",
    "    '''\n",
    "    arr = transposed_arr.transpose()\n",
    "    new_df = pd.DataFrame(arr, columns=df.columns)\n",
    "    return new_df\n",
    "\n",
    "\n",
    "# Function, .................................\n",
    "def log_transformer(x):\n",
    "    ''' log1p scaller for input dataframe (x)\n",
    "        CAUTION: log1p returns runtime warning if negative data are used'''\n",
    "    log_transformer = make_pipeline( \n",
    "        FunctionTransformer(np.log1p, validate=False),\n",
    "    )\n",
    "    x_log = pd.DataFrame(\n",
    "        log_transformer.fit_transform(x),\n",
    "        columns=x.columns\n",
    "    )\n",
    "    return x_log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefea7e7-61f7-4cc1-a624-2f46b3c8c795",
   "metadata": {},
   "source": [
    "__get some automated diagnostic to have idea whether transformer does its job correctly__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "27db3d74-1071-47ec-aed0-b5754c878943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tpm_summary(df_list, name_list=None):\n",
    "    ''' Creates tpm cummary table for several dataframes provided in the list (df_list)\n",
    "        colnames - list with columns names for new summary table \n",
    "        for more ifo see help for tpm_summary() \n",
    "    '''\n",
    "    for i, df in enumerate(df_list):\n",
    "        if i==0:\n",
    "            summary_table = tpm_summary(df=df)\n",
    "        else:\n",
    "            summary_table =  pd.concat([summary_table, tpm_summary(df=df)])\n",
    "    \n",
    "    # transpose for nice looking output\n",
    "    summary_table = summary_table.transpose() \n",
    "    \n",
    "    # add column names corresponding to different df's\n",
    "    if(name_list is not None):\n",
    "        summary_table.columns=name_list\n",
    "    else:\n",
    "        summary_table.columns=list(range(len(df_list)))\n",
    "    \n",
    "    return summary_table\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2265cc4d-7299-4096-8811-7a7abe2d6e4a",
   "metadata": {},
   "source": [
    "__Create custom funciton for detecting differencially expressed genes, between the two classe with tstudent test and foldchnage__\n",
    "* I applied this, method, as the siples possible option, \n",
    "* it can be replaced at any moent with another method, \n",
    "* more informaiton on the topic can be found here:\n",
    "    * \"Detecting differentially expressed genes in heterogeneous diseases using half Student’s t-test\" https://academic.oup.com/ije/article/39/6/1597/736515\n",
    "    * \"Robustness of differential gene expression analysis of RNA-seq\" https://doi.org/10.1016/j.csbj.2021.05.040"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9c71f7-de57-46e9-8675-6a709cb766ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_genes(x, y):\n",
    "    ''' simple funciton that calulates gene expression foldchnage between two classes of samples\n",
    "        and ttstudent test, then it data frame, with list of all genes, sorted with pvalue from ttest, \n",
    "        from the most, to the least signifficant,\n",
    "        . x, y - dataframe and pd. series repsectively, with the data, and labels, \n",
    "        \n",
    "        important: ttest shoudl be used only with relatively large number of replicates in each gorup, \n",
    "        eg >20, For more informaiton see these articles:\n",
    "    \n",
    "        > \"Detecting differentially expressed genes in heterogeneous diseases using half Student’s t-test\"\n",
    "           https://academic.oup.com/ije/article/39/6/1597/736515\n",
    "        \n",
    "        > \"Robustness of differential gene expression analysis of RNA-seq\"\n",
    "           https://doi.org/10.1016/j.csbj.2021.05.040\n",
    "        \n",
    "    '''\n",
    "    # test input df, & work on df copy,\n",
    "    assert type(x_train) == pd.DataFrame, \"x_train Incorrect obj type\"\n",
    "    x_train = x_train.copy()\n",
    "    assert type(y_train) == pd.Series, \"y_train Incorrect obj type\"\n",
    "    y_train = y_train.copy()\n",
    "        \n",
    "    # divide the set into two group\n",
    "    ttest_results=[]\n",
    "    fold_change_results=[]\n",
    "    for idx in range(x.shape[1]):\n",
    "        one_row = x_transf.iloc[:,idx].values\n",
    "        a = one_row[y==0]\n",
    "        b = one_row[y==1]\n",
    "\n",
    "        # .. ttest\n",
    "        ttest_results.append((stats.ttest_ind(a, b).pvalue))\n",
    "\n",
    "        # log chnage\n",
    "        fold_change_results.append(np.abs(np.median(a)-np.median(b))/np.median(a))\n",
    "\n",
    "    # store results in nice dataframe\n",
    "    ttest_results = pd.DataFrame([ttest_results,fold_change_results]).transpose()\n",
    "    ttest_results.columns = ['pvalues', 'foldchange']\n",
    "    ttest_results.index = x.columns   \n",
    "    \n",
    "    return ttest_results.sort_values(by=\"pvalues\", ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf3868c-cb7a-4ec5-a57c-55537c39b9ed",
   "metadata": {},
   "source": [
    "__create main preprocessing function__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3258ac26-b381-496e-a66f-12f898738d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function, .................................\n",
    "def prepare_tpm_data(\n",
    "    x_train, y_train, noise_tr=0.5, sp_filter_tr=0.95, sp_filter_quantile=True):\n",
    "    \n",
    "    # - instanciate transformers ..........................................\n",
    "    robust_scaler = RobustScaler() \n",
    "    zv_filter = ZeroValueFilter() # custom build for the project \n",
    "    sp_filter = SpearmanFilter() # custom build for the project \n",
    "\n",
    "    # - fit_transform train data ...........................................\n",
    "\n",
    "    # test input df, & work on df copy,\n",
    "    assert type(x_train) == pd.DataFrame, \"x_train Incorrect obj type\"\n",
    "    x_train = x_train.copy()\n",
    "    assert type(y_train) == pd.Series, \"y_train Incorrect obj type\"\n",
    "    y_train = y_train.copy()\n",
    "        \n",
    "    # step 1. log1p to combat heteroscedascity,- no params\n",
    "    x_train_log = log_transformer(x=x_train)\n",
    "\n",
    "    # step 2. remove genes with too much noise,\n",
    "    x_train_log_filtered = zv_filter.fit_transform(x_train_log, na_tr=noise_tr)\n",
    "\n",
    "    # step 3. robuscaller - transpose to work per sample\n",
    "    arr = robust_scaler.fit_transform(x_train_log_filtered.transpose())\n",
    "    # rebuild original df, shape\n",
    "    x_train_log_filtered_scaled = transpose_rebuild(arr, x_train_log_filtered)\n",
    "\n",
    "    # step 4. remove potential outliers from train data - params to set\n",
    "    x_train_transf, y_train_transf = sp_filter.fit_transform(\n",
    "        x=x_train_log_filtered_scaled, \n",
    "        y=y_train, \n",
    "        tr=sp_filter_tr,\n",
    "        quantile=sp_filter_quantile\n",
    "    )\n",
    "    \n",
    "    # ...... info .......\n",
    "    report = make_tpm_summary(\n",
    "        df_list=[x_train, x_train_log, x_train_log_filtered,  x_train_log_filtered_scaled, x_train_transf],\n",
    "        name_list=['input', 'log', 'log_filtered',  'log_filtered_scaled', 'outliers_removed']\n",
    "        )\n",
    "    \n",
    "    #return x_traint_ransf, y_train_transf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "433a0856-8e53-43b9-a0bb-4f64bed8ad3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_tpm_data(\n",
    "    x_train=data_genes,\n",
    "    y_train=pd.Series(target.iloc[:,0])\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b6d49e-081f-4ea3-9d63-01306291e18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a9e40e95-efa8-4ed9-8aba-51a10dd5fb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_genes(x, y):\n",
    "    ''' simple funciton that calulates gene expression foldchnage between two classes of samples\n",
    "        and ttstudent test, then it data frame, with list of all genes, sorted with pvalue from ttest, \n",
    "        from the most, to the least signifficant,\n",
    "        . x, y - dataframe and pd. series repsectively, with the data, and labels, \n",
    "        \n",
    "        important: ttest shoudl be used only with relatively large number of replicates in each gorup, \n",
    "        eg >20, For more informaiton see these articles:\n",
    "    \n",
    "        > \"Detecting differentially expressed genes in heterogeneous diseases using half Student’s t-test\"\n",
    "           https://academic.oup.com/ije/article/39/6/1597/736515\n",
    "        \n",
    "        > \"Robustness of differential gene expression analysis of RNA-seq\"\n",
    "           https://doi.org/10.1016/j.csbj.2021.05.040\n",
    "        \n",
    "    '''\n",
    "    # test input df, & work on df copy,\n",
    "    assert type(x_train) == pd.DataFrame, \"x_train Incorrect obj type\"\n",
    "    x_train = x_train.copy()\n",
    "    assert type(y_train) == pd.Series, \"y_train Incorrect obj type\"\n",
    "    y_train = y_train.copy()\n",
    "        \n",
    "    # divide the set into two group\n",
    "    ttest_results=[]\n",
    "    fold_change_results=[]\n",
    "    for idx in range(x.shape[1]):\n",
    "        one_row = x_transf.iloc[:,idx].values\n",
    "        a = one_row[y==0]\n",
    "        b = one_row[y==1]\n",
    "\n",
    "        # .. ttest\n",
    "        ttest_results.append((stats.ttest_ind(a, b).pvalue))\n",
    "\n",
    "        # log chnage\n",
    "        fold_change_results.append(np.abs(np.median(a)-np.median(b))/np.median(a))\n",
    "\n",
    "    # store results in nice dataframe\n",
    "    ttest_results = pd.DataFrame([ttest_results,fold_change_results]).transpose()\n",
    "    ttest_results.columns = ['pvalues', 'foldchange']\n",
    "    ttest_results.index = x.columns   \n",
    "    \n",
    "    return ttest_results.sort_values(by=\"pvalues\", ascending=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba340b0-8589-4e80-8401-4988592ae3cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8dc299-04d2-4524-8313-4e201426b83f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecf4b42-4139-4590-a243-d1983c301727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "x = x_transf\n",
    "y = y_transf\n",
    "\n",
    "# divide the set into two group\n",
    "ttest_results=[]\n",
    "fold_change_results=[]\n",
    "for idx in range(x.shape[1]):\n",
    "    one_row = x_transf.iloc[:,idx].values\n",
    "    a = one_row[y==0]\n",
    "    b = one_row[y==1]\n",
    "    \n",
    "    # .. ttest\n",
    "    ttest_results.append((stats.ttest_ind(a, b).pvalue))\n",
    "    \n",
    "    # log chnage\n",
    "    fold_change_results.append(np.abs(np.median(a)-np.median(b))/np.median(a))\n",
    "    \n",
    "# store results in nice series\n",
    "ttest_results = pd.DataFrame([ttest_results,fold_change_results]).transpose()\n",
    "ttest_results.columns = ['pvalues', 'foldchange']\n",
    "ttest_results.index = x.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
